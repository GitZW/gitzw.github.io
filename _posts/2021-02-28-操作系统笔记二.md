---
layout:     post
title:      操作系统 学习笔记（二）
subtitle:   操作系统 学习笔记（二）
date:       2021-02-28
author:     ZW
header-img: img/mysql_img.jpg
catalog: 	 true
tags:
    - 操作系统
---


# 每个进程特点

1. 逻辑地址空间是一个抽象模型。
2. 保护独立地址空间。P1进程只能访问自己的地址空间，不能意外跨越去访问P2的地址空间；
3. 共享。进程P1, P2, … , 又是共享操作系统内核的
4. 虚拟化。每个进程的逻辑地址空间都是一致的，都是从地址0X0000开始。

# 内存管理方式
1. 重定位 relocation
2. 分段 segmentation
3. 分页 paging
4. 虚拟存储 virtual memory

目前大多数系统，如 Linux 采用按页式虚拟存储。

# 地址空间
物理地址空间----硬件支持的地址空间

逻辑地址空间----- 一个运行的程序所拥有的内存范围

逻辑地址生成：编译，汇编，链接，载入（程序重定位）

操作系统 建立逻辑地址和地址之间的映射

地址生成及处理过程：
>ALU需要逻辑地址中的内容（读或写），
MMU对逻辑地址进行转换，转换为物理地址，
CPU控制逻辑给总线发送物理地址请求。
内存发送物理地址的内容给CPU或者将CPU给的数据存储到物理地址。操作系统做的是简历逻辑地址LA和物理地址PA之间的映射。

地址检查：
>CPU执行到某条指令，得到它的逻辑地址，首先根据逻辑地址判断所在它的偏移量是否在所在段（比如数据段）的长度之内，如果超出了段长度，认为是非法请求，否则认为是合法的。此时加上段基址得到物理地址，进行访问。在这个过程中操作系统要做的就是设置段起始地址和最大逻辑地址空间（段长度）。

# 连续地址分配
## 内存碎片
内存碎片：有的还可以用，有的无论如何都用不起来了。

外部碎片：分配单元之间的未被使用内存

内部碎片：分配单元内部的未被使用内存（你只占500字节，但是不得不分配512字节）

## 分配策略
1. 最先匹配(First Fit Allocation)策略。
> 空闲分区列表按地址顺序排序
分配过程时，搜索一个合适的分区
释放分区时，检查是否可与临近的空闲分区合并

2. 最佳匹配(Best Fit Allocation)策略
> 空闲分区列表按照大小排序
分配时，查找一个合适的分区
释放时，查找并且合并临近的空闲分区（如果找到）


3. 最差匹配(Worst Fit Allocation)策略
> 空闲分区列表按由大到小排序
分配时，选最大的分区
释放时，检查是否可与临近的空闲分区合并，进行可能的合并，并调整空闲分区列表顺序


## 碎片整理
### 碎片紧凑

实现方式：通过移动分配给进程的内存分区，以合并外部碎片。

条件：所有的应用程序可以动态重定位。这是因为程序中可能有很多地址引用，如果引用了绝对地址，移动分配的内存位置可能就会出错。因此需要动态重定位，执行到命令的时候才生成内存地址。

时机：进程处于等待状态时搬动。

开销：移动已分配的内存分区是有开销的，因此不会为了一小块碎片就进行紧凑。具体开销暂且按下不讲。

### 分区对换
>分区对换是通过抢占并回收处于等待状态进程的分区，以增大可用内存空间。即将等待状态进程的数据存储到外存中，也就是对换到对换区


## 伙伴系统
>伙伴系统是一个结合了2的方幂个分配器和空闲缓冲区合并计技术的内存分配方案, 其基本思想很简单. 内存被分成含有很多页面的大块, 每一块都是2个页面大小的方幂. 如果找不到想要的块, 一个大块会被分成两部分, 这两部分彼此就成为伙伴. 其中一半被用来分配, 而另一半则空闲. 这些块在以后分配的过程中会继续被二分直至产生一个所需大小的块. 当一个块被最终释放时, 其伙伴将被检测出来, 如果伙伴也空闲则合并两者


# 非连续内存分配

## 连续内存分配缺点
1. 分配给程序的物理内存必须连续

2. 存在外碎片和内碎片

3. 内存分配的动态修改困难

4. 内存利用效率低


## 非连续分配设计目标
提高内存利用效率和管理灵活性

允许一个程序的使用非连续的物理地址空间

允许共享代码与数据

支持动态加载和动态链接

## 如何实现虚拟地址和物理地址的转换

软件实现(灵活,开销大)

硬件实现(够用，开销小)


## 段式存储管理
页式存储方式，是以计算机的角度设计的，以便提高内存的利用率和计算机的性能，且分页机制是通过硬件实现的。对用户而言是完全透明的段式存储器的引入，主要是为了满足用户在编程和使用上的要求。具体来说：

1. 方便编程。因为人们写的程序是分成了许多个段的，比如一个程序里面有很多和函数等等

2. 段的共享。实现程序和数据的共享，都是以信息的逻辑单位为基础的。比如一些公共函数，一些全局变量等等。

3. 动态链接。动态链接是程序在运行的过程中实现目标模块的链接，动态链接同样要求以段为存储管理的单位。（写过dll的同学应该深有体会，里面就是一些类库）

4. 动态增长。程序运行过程中，往往有些段，特别是数据段，会不断的往上增长。而分页确实固定的。

5. 段的保护

## 页式存储管理
> 将内存空间分成大小相同的存储块，并按顺序编号（一般从0开始）。相应的将进程的逻辑地址空间分成若干个与内存块大小相等的块，但是为了方便区分，我们称为页。（也就是说，在实际的内存中我们称为块，在逻辑地址中我们称为页）。在为进程分配内存空间的时候，以页为单位进行。进程中若干个页分别装入多个不相邻的存储块中，通常，进程的最后一页通常装不满一个存储块，形成不可利用的碎片，称为页内碎片。

### 页式存储的地址变换
1. 首先，页号与页表寄存器中的页表长度进行比较，若页号大于页表长度，则产生越界中断。（判越界）

2. 否则，通过页表起始地址，找出页表。

3. 根据页号，找出相应的页表项，得到该页的存储块号

4. 根据块号与页内偏移，算出实际的物理地址

### 页式存储管理的性能问题
1. 内存访问性能问题：访问一个内存单元需要两次内存访问，第一次访问获取页表项，第二次访问获取数据，这样与连续内存分配相比，读写的性能大幅下降
2. 页表大小问题：当内存空间很大时，页表可能会非常大，页表的容量是不可忽视的，比如32位的机器，内存大小为4G，假设页面的大小是1K，则一共有222个页面，每个页表项的地址为4个字节，整个页表的大小为224个字节，也就是16M。而且每个进程都有一个页表，100个进程仅页面大小就有1600M，这是无法忽视的

解决：
1. 采用Cache：利用局部性原理，减少缓存次数，TLB（快表）
2. 间接访问：多级页表，将一个长的页表切分成多个字表，先确定在哪个字表中，再去子表中寻找。（多级页表）

### 快表和多级页表
快表 ：快表中缓存近期访问的页表项。TLB条目由两部分组成：键（标签）和值。当关联内存通过给定值查找时，它会同时与所有的键进行比较。

多级页表： 多级页表是通过间接引用，将页号分成多级

### 反置页表
反置页表与物理地址挂钩，对于每个真正的内存页或者帧才有一个条目。每个条目包含保存在真正内存位置的页的虚拟地址以及拥有该页的进程信息。因此，整个系统只有一个页表，对每个物理内存的页只有一条相应的条目。此时进程的增加和逻辑地址空间的增大都对页表占用的空间没有影响。

### 段页式存储
> 在段式存储管理的基础上，给每个段增加一个一级页表（多级也可以），从而将逻辑地址变为段号+页号+页内偏移，由逻辑地址转化为物理地址时，先根据段号找到相应的段表项，得到段的页表的起始位置，在根据页号在页表中找到帧号，帧号与页内偏移加起来就找到了响应的物理地址。


# 虚拟存储
虚拟存储是想把一部分内存中的内容暂时存放到外存中，以提供更大的内存空间。

## 覆盖和交换
覆盖：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区。其余部分按调用关系 分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

交换：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这个过程叫做换出。把准备好竞争CPU运行的程序从辅存移到内存，这个过程又称为换入